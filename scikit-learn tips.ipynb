{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤–âš¡ **scikit-learn tips**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference material to pull up when using scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns by data type\n",
    "num_cols = make_column_selector(dtype_include='number')\n",
    "cat_cols = make_column_selector(dtype_exclude='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four options for handling missing values (NaNs):\n",
    "\n",
    "Drop rows containing NaNs  \n",
    "Drop columns containing NaNs  \n",
    "Fill NaNs with imputed values  \n",
    "Use a model that natively handles NaNs (NEW!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()\n",
    "# Categorical\n",
    "imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# add an indicator matrix to show missingness as a new feature. missing = 1, value =  imputed mean\n",
    "imputer = SimpleImputer(add_indicator=True)\n",
    "\n",
    "\n",
    "# Try KNNImputer or IterativeImputer (inspired by R's MICE package). \n",
    "# Both are multivariate approaches (they take other features into account!)\n",
    "\n",
    "impute_it = IterativeImputer()\n",
    "impute_knn = KNNImputer(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't use drop='first' with OneHotEncoder. Here's why:\n",
    "\n",
    "1. Multicollinearity is rarely an issue with scikit-learn models\n",
    "2. drop='first' is incompatible with handle_unknown='ignore'\n",
    "3. May be problematic if you standardize all features or use a regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-to-right column order is alphabetical (circle, oval, square)\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore') # category that has not been learnt in fit step is encoded as all zeros\n",
    "\n",
    "# category ordering (within each feature) is defined by you\n",
    "oe = OrdinalEncoder(categories=[['first', 'second', 'third'], ['S', 'M', 'L', 'XL']])\n",
    "oe.fit_transform(X[['Class', 'Size']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use drop='if_binary' with OneHotEncoder to drop the first category ONLY if it's a binary feature (meaning it has exactly two categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop='first' drops the first category in each feature\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "ohe.fit_transform(X)\n",
    "\n",
    "# drop='if_binary' drops the first category of binary features\n",
    "ohe = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "ohe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a tree-based model, try OrdinalEncoder instead of OneHotEncoder even for nominal (unordered) features.\n",
    "\n",
    "Accuracy will often be similar, but OrdinalEncoder will be much faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests is a tree-based model\n",
    "rf = RandomForestClassifier(random_state=1, n_jobs=-1)\n",
    "\n",
    "# Pipeline containing OneHotEncoder\n",
    "ohe_pipe = make_pipeline(ohe, rf)\n",
    "%time cross_val_score(ohe_pipe, X, y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need all the features in the one hot encoding. if the feature is binary then just having one of the ohe vectors is sufficent to give full info. same with multi values features. you can drop the first one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with Nans you can still run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf = HistGradientBoostingClassifier()\n",
    "# no errors, despite NaNs in train and test!\n",
    "clf.fit(train, label)\n",
    "clf.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create more features based on interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial relationships between features\n",
    "poly = PolynomialFeatures(include_bias=False, interaction_only=True)\n",
    "poly.fit_transform(X)\n",
    "\n",
    "# Input columns: A, B, C\n",
    "# Output columns: A, B, C, A*B, A*C, B*C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline requires naming of steps, make_pipeline does not.\n",
    "\n",
    "(Same applies to ColumnTransformer vs make_column_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')\n",
    "pipe = make_pipeline(ct, clf)\n",
    "#-----------------------------------\n",
    "ct = ColumnTransformer(\n",
    "    [('encoder', ohe, ['Embarked', 'Sex']),\n",
    "     ('imputer', imp, ['Age'])],\n",
    "    remainder='passthrough')\n",
    "pipe = Pipeline([('preprocessor', ct), ('classifier', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute A, passthrough B & C, then drop the remaining columns\n",
    "ct = make_column_transformer(\n",
    "    (impute, ['A']),\n",
    "    ('passthrough', ['B', 'C']),\n",
    "    remainder='drop')\n",
    "\n",
    "# impute A, drop D & E, then passthrough the remaining columns\n",
    "ct = make_column_transformer(\n",
    "    (impute, ['A']),\n",
    "    ('drop', ['D', 'E']),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names of those one-hot encoded features\n",
    "ct.get_feature_names() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding feature selection to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "\n",
    "# keep 50% of features with the best chi-squared scores\n",
    "selection = SelectPercentile(chi2, percentile=50)\n",
    "pipe = make_pipeline(vect, selection, clf)\n",
    "\n",
    "cross_val_score(pipe, X, y, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "ct = make_column_transformer((vect, 'Name'), (vect, 'Cabin'))\n",
    "ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Lambda function transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "clip_values = FunctionTransformer(np.clip, kw_args={'a_min':100, 'a_max':600})\n",
    "\n",
    "# extract the first letter from each string\n",
    "def first_letter(df):\n",
    "    return df.apply(lambda x: x.str.slice(0, 1))\n",
    "get_first_letter = FunctionTransformer(first_letter)\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (clip_values, ['Fare']),\n",
    "    (get_first_letter, ['Code', 'Deck']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the pipeline and make iiit interactive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display estimators as diagrams\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "pipe = make_pipeline(ct, selection, logreg)\n",
    "pipe\n",
    "\n",
    "# export the diagram to a file\n",
    "from sklearn.utils import estimator_html_repr\n",
    "with open('pipeline.html', 'w') as f:  \n",
    "    f.write(estimator_html_repr(pipe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing parts of the pipeline individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Pipeline\n",
    "pipe = Pipeline([('preprocessor', ct), ('feature selector', fs), ('classifier', clf)])\n",
    "pipe\n",
    "\n",
    "# access step 0 (preprocessor)\n",
    "pipe[0].fit_transform(X)\n",
    "\n",
    "# access steps 0 and 1 (preprocessor and feature selector)\n",
    "pipe[0:2].fit_transform(X, y)\n",
    "\n",
    "# access step 1 (feature selector)\n",
    "pipe[1].get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validate the entire pipeline (not just the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch - Find optimal tuning parameters for the entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameter values to search\n",
    "params = {}\n",
    "params['columntransformer__countvectorizer__min_df'] = [1, 2]\n",
    "params['logisticregression__C'] = [0.1, 1, 10]\n",
    "params['logisticregression__penalty'] = ['l1', 'l2']\n",
    "\n",
    "\n",
    "# try all possible combinations of those parameter values\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y);\n",
    "\n",
    "# what was the best score found during the search?\n",
    "grid.best_score_\n",
    "\n",
    "\n",
    "# which combination of parameters produced the best score?\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tune 2+ models using the same grid search! Here's how:\n",
    "\n",
    "Create multiple parameter dictionaries  \n",
    "Specify the model within each dictionary  \n",
    "Put the dictionaries in a list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each of these models will take a turn as the second Pipeline step\n",
    "clf1 = LogisticRegression(solver='liblinear', random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "# create the Pipeline\n",
    "pipe = Pipeline([('preprocessor', ct), ('classifier', clf1)])\n",
    "\n",
    "# create the parameter dictionary for clf1\n",
    "params1 = {}\n",
    "params1['preprocessor__vectorizer__ngram_range'] = [(1, 1), (1, 2)]\n",
    "params1['classifier__penalty'] = ['l1', 'l2']\n",
    "params1['classifier__C'] = [0.1, 1, 10]\n",
    "params1['classifier'] = [clf1]\n",
    "# create the parameter dictionary for clf2\n",
    "params2 = {}\n",
    "params2['preprocessor__vectorizer__ngram_range'] = [(1, 1), (1, 2)]\n",
    "params2['classifier__n_estimators'] = [100, 200]\n",
    "params2['classifier__min_samples_leaf'] = [1, 2]\n",
    "params2['classifier'] = [clf2]\n",
    "\n",
    "\n",
    "# create a list of parameter dictionaries\n",
    "params = [params1, params2]\n",
    "\n",
    "# this will search every parameter combination within each dictionary\n",
    "grid = GridSearchCV(pipe, params)\n",
    "grid.fit(X, y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV taking too long? Try RandomizedSearchCV with a small number of iterations.\n",
    "\n",
    "Make sure to specify a distribution (instead of a list of values) for continuous parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try \"n_iter\" random combinations of those parameter values\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rand = RandomizedSearchCV(pipe, params, n_iter=10, cv=5, scoring='accuracy', random_state=1)\n",
    "rand.fit(X, y);\n",
    "\n",
    "# what was the best score found during the search?\n",
    "rand.best_score_\n",
    "\n",
    "\n",
    "# which combination of parameters produced the best score?\n",
    "rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter search results (from GridSearchCV or RandomizedSearchCV) can be converted into a pandas DataFrame.\n",
    "\n",
    "Makes it far easier to explore the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results into a DataFrame\n",
    "results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'rank_test_score']]\n",
    "# sort by test score\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parallel to finish quicker\n",
    "grid = GridSearchCV(pipe, params, n_jobs=-1)\n",
    "%time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass it a trained model: it makes predictions for X_test and compares them to y_test\n",
    "disp = plot_confusion_matrix(clf, X_test, y_test, cmap='Blues', values_format='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display mutiple AUROC curves to compare classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train);\n",
    "dt.fit(X_train, y_train);\n",
    "rf.fit(X_train, y_train);\n",
    "\n",
    "disp = plot_roc_curve(lr, X_test, y_test)\n",
    "plot_roc_curve(dt, X_test, y_test, ax=disp.ax_);\n",
    "plot_roc_curve(rf, X_test, y_test, ax=disp.ax_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display decision tree as either image or text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree, export_text  # both are new in 0.21\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_tree(dt, feature_names=features, class_names=classes, filled=True);\n",
    "\n",
    "print(export_text(dt, feature_names=features, show_weights=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prune or cut down on number of nodes for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning \n",
    "\n",
    "# default tree has 331 nodes\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X, y).tree_.node_count\n",
    "\n",
    "\n",
    "# pruned tree has 121 nodes\n",
    "dt = DecisionTreeClassifier(ccp_alpha=0.001, random_state=0)\n",
    "dt.fit(X, y).tree_.node_count\n",
    "\n",
    "# pruning improved the cross-validated accuracy\n",
    "cross_val_score(dt, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pipeline to a file\n",
    "import joblib\n",
    "joblib.dump(pipe, 'pipe.joblib')\n",
    "\n",
    "# load the pipeline from a file\n",
    "same_pipe = joblib.load('pipe.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# For Regression\n",
    "kf = KFold(5, shuffle=True, random_state=1)\n",
    "cross_val_score(reg, X_reg, y_reg, cv=kf, scoring='r2')\n",
    "\n",
    "\n",
    "# For Classification\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
    "cross_val_score(clf, X_clf, y_clf, cv=skf, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Multi-class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_score = clf.predict_proba(X_test)\n",
    "\n",
    "# use 'ovo' (One-vs-One) or 'ovr' (One-vs-Rest)\n",
    "roc_auc_score(y_test, y_score, multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# use 'roc_auc_ovo' (One-vs-One) or 'roc_auc_ovr' (One-vs-Rest)\n",
    "cross_val_score(clf, X, y, cv=5, scoring='roc_auc_ovo').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no need to use \".values\" when passing a DataFrame or Series to scikit-learn... it knows how to access the underlying NumPy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "<class 'pandas.core.series.Series'>\n",
    "\n",
    "# there's no need to use X.values or y.values\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state=1)\n",
    "rf = RandomForestClassifier(max_features=None, random_state=1)\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an ensemble for improved accuracy\n",
    "vc = VotingClassifier([('clf1', lr), ('clf2', rf)], voting='soft')\n",
    "cross_val_score(vc, X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an ensemble of 3 classifiers\n",
    "vc = VotingClassifier([('clf1', lr), ('clf2', rf), ('clf3', nb)])\n",
    "cross_val_score(vc, X, y).mean()\n",
    "\n",
    "# define VotingClassifier parameters to search\n",
    "params = {'voting':['hard', 'soft'],\n",
    "          'weights':[(1,1,1), (2,1,1), (1,2,1), (1,1,2)]}\n",
    "\n",
    "# find the best set of parameters\n",
    "grid = GridSearchCV(vc, params)\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_params_\n",
    "{'voting': 'soft', 'weights': (1, 2, 1)}\n",
    "\n",
    "# accuracy has improved\n",
    "grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn-tricks",
   "language": "python",
   "name": "scikit-learn-tricks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
