{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤–âš¡ **scikit-learn tips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns by data type\n",
    "num_cols = make_column_selector(dtype_include='number')\n",
    "cat_cols = make_column_selector(dtype_exclude='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four options for handling missing values (NaNs):\n",
    "\n",
    "Drop rows containing NaNs  \n",
    "Drop columns containing NaNs  \n",
    "Fill NaNs with imputed values  \n",
    "Use a model that natively handles NaNs (NEW!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer()\n",
    "\n",
    "# add an indicator matrix to show missingness as a new feature. missing = 1, value =  imputed mean\n",
    "imputer = SimpleImputer(add_indicator=True)\n",
    "\n",
    "\n",
    "# Try KNNImputer or IterativeImputer (inspired by R's MICE package). \n",
    "# Both are multivariate approaches (they take other features into account!)\n",
    "\n",
    "impute_it = IterativeImputer()\n",
    "impute_knn = KNNImputer(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't use drop='first' with OneHotEncoder. Here's why:\n",
    "\n",
    "1. Multicollinearity is rarely an issue with scikit-learn models\n",
    "2. drop='first' is incompatible with handle_unknown='ignore'\n",
    "3. May be problematic if you standardize all features or use a regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left-to-right column order is alphabetical (circle, oval, square)\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore') # category that has not been learnt in fit step is encoded as all zeros\n",
    "\n",
    "# category ordering (within each feature) is defined by you\n",
    "oe = OrdinalEncoder(categories=[['first', 'second', 'third'], ['S', 'M', 'L', 'XL']])\n",
    "oe.fit_transform(X[['Class', 'Size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf = HistGradientBoostingClassifier()\n",
    "# no errors, despite NaNs in train and test!\n",
    "clf.fit(train, label)\n",
    "clf.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline requires naming of steps, make_pipeline does not.\n",
    "\n",
    "(Same applies to ColumnTransformer vs make_column_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = make_column_transformer(\n",
    "    (ohe, ['Embarked', 'Sex']),\n",
    "    (imp, ['Age']),\n",
    "    remainder='passthrough')\n",
    "pipe = make_pipeline(ct, clf)\n",
    "#-----------------------------------\n",
    "ct = ColumnTransformer(\n",
    "    [('encoder', ohe, ['Embarked', 'Sex']),\n",
    "     ('imputer', imp, ['Age'])],\n",
    "    remainder='passthrough')\n",
    "pipe = Pipeline([('preprocessor', ct), ('classifier', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate the entire pipeline (not just the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal tuning parameters for the entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameter values to search\n",
    "params = {}\n",
    "params['columntransformer__countvectorizer__min_df'] = [1, 2]\n",
    "params['logisticregression__C'] = [0.1, 1, 10]\n",
    "params['logisticregression__penalty'] = ['l1', 'l2']\n",
    "\n",
    "\n",
    "# try all possible combinations of those parameter values\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y);\n",
    "\n",
    "# what was the best score found during the search?\n",
    "grid.best_score_\n",
    "\n",
    "\n",
    "# which combination of parameters produced the best score?\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV taking too long? Try RandomizedSearchCV with a small number of iterations.\n",
    "\n",
    "Make sure to specify a distribution (instead of a list of values) for continuous parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try \"n_iter\" random combinations of those parameter values\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rand = RandomizedSearchCV(pipe, params, n_iter=10, cv=5, scoring='accuracy', random_state=1)\n",
    "rand.fit(X, y);\n",
    "\n",
    "# what was the best score found during the search?\n",
    "rand.best_score_\n",
    "\n",
    "\n",
    "# which combination of parameters produced the best score?\n",
    "rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter search results (from GridSearchCV or RandomizedSearchCV) can be converted into a pandas DataFrame.\n",
    "\n",
    "Makes it far easier to explore the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results into a DataFrame\n",
    "results = pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'rank_test_score']]\n",
    "# sort by test score\n",
    "results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass it a trained model: it makes predictions for X_test and compares them to y_test\n",
    "disp = plot_confusion_matrix(clf, X_test, y_test, cmap='Blues', values_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn-tricks",
   "language": "python",
   "name": "scikit-learn-tricks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
